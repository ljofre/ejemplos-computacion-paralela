{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a MPI\n",
    "\n",
    "Bibliografía\n",
    "==\n",
    "\n",
    "<a href=\"http://computing.llnl.gov/tutorials/mpi/\">Message Passing Interface (MPI)</a>\n",
    "\n",
    "<a href=\"http://mpitutorial.com/tutorials/running-an-mpi-cluster-within-a-lan/\">Running an MPI Cluster within a LAN</a>\n",
    "\n",
    "<a href=\"http://condor.cc.ku.edu/~grobe/docs/intro-MPI-C.shtml\">An introduction to the \n",
    "Message Passing Interface (MPI) using C</a>\n",
    "\n",
    "<a href=\"http://condor.cc.ku.edu/~grobe/docs/intro-MPI.shtml\">An introduction to the \n",
    "Message Passing Interface (MPI) using Fortran</a>\n",
    "\n",
    "<a href=\"http://math-cs.gordon.edu/courses/cps343/presentations/MPI_Collective.pdf\"> MPI_Collective.pdf </a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hello world\n",
    "\n",
    "\n",
    "```c\n",
    "//hello.c\n",
    "#include <stdio.h>\n",
    "#include <mpi.h>\n",
    "\n",
    "int main(int argc, char **argv) \n",
    "{\n",
    "  int ierr;\n",
    "\n",
    "  ierr = MPI_Init(&argc, &argv);\n",
    "  printf(\"Hello world\\n\"); \n",
    "\n",
    "  ierr = MPI_Finalize();\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "luego compilamos el archivo\n",
    "\n",
    "```bash\n",
    "mpicc hello.c -o hello\n",
    "```\n",
    "\n",
    "para finalmente ejecutarlo\n",
    "```bash\n",
    "mpirun -np 4 hello\n",
    "```\n",
    "\n",
    "la respuesta debería ser\n",
    "```bash\n",
    "Hello world\n",
    "Hello world\n",
    "Hello world\n",
    "Hello world\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificar el número de procesadores y el procesador actual\n",
    "\n",
    "Las funciones de mpi *MPI_Comm_rank* y *MPI_Comm_size* nos permiten identificar el id del procesador que estamos usando y la cantidad de procesadores que estamos usando, respectivamente. Acá un ejemplo:\n",
    "\n",
    "```c\n",
    "//hello2.c\n",
    "#include <stdio.h>\n",
    "#include <mpi.h>\n",
    "\n",
    "int main(int argc, char **argv)\n",
    "{\n",
    "  int ierr, num_procs, my_id;\n",
    "\n",
    "  ierr = MPI_Init(&argc, &argv);\n",
    "\n",
    "  /* find out MY process ID, and how many processes were started. */\n",
    "\n",
    "  ierr = MPI_Comm_rank(MPI_COMM_WORLD, &my_id);\n",
    "  ierr = MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n",
    "\n",
    "  printf(\"Hello world! I'm process %i out of %i processes\\n\", \n",
    "     my_id, num_procs);\n",
    "\n",
    "  ierr = MPI_Finalize();\n",
    "  \n",
    "  return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "compilamos\n",
    "```bash\n",
    "mpicc hello2.c -o hello2\n",
    "```\n",
    "\n",
    "ejecutamos en este caso con 4 procesadores\n",
    "```bash\n",
    "mpirun -np 4 hello2\n",
    "```\n",
    "\n",
    "finalmente obtenemos como resultado lo siguiente\n",
    "\n",
    "```bash\n",
    "\n",
    "Hello world! I'm process 1 out of 4 processes\n",
    "Hello world! I'm process 3 out of 4 processes\n",
    "Hello world! I'm process 2 out of 4 processes\n",
    "Hello world! I'm process 0 out of 4 processes\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código en función del Rank\n",
    "\n",
    "Este es un ejemplo de como identificar la variable rank y tomar desiciones en función de esta\n",
    "\n",
    "```c\n",
    "#include <mpi.h>\n",
    "int main(int argc, char **argv)\n",
    "   {\n",
    "      int my_id, root_process, ierr, num_procs;\n",
    "      MPI_Status status;\n",
    "\n",
    "      ierr = MPI_Init(&argc, &argv); \n",
    "      ierr = MPI_Comm_rank(MPI_COMM_WORLD, &my_id);\n",
    "      ierr = MPI_Comm_size(MPI_COMM_WORLD, &num_procs);\n",
    "\n",
    "      if( my_id == 0 ) {\n",
    "\n",
    "         /* do some work as process 0 */\n",
    "      }\n",
    "      else if( my_id == 1 ) {\n",
    "\n",
    "         /* do some work as process 1 */\n",
    "      }\n",
    "      else if( my_id == 2 ) {\n",
    "\n",
    "         /* do some work as process 2 */ \n",
    "      } \n",
    "      else {\n",
    "\n",
    "         /* do this work in any remaining processes */\n",
    "      }\n",
    "      /* Stop this process */\n",
    "\n",
    "      ierr = MPI_Finalize();\n",
    "        \n",
    "      return 0;\n",
    "   }\n",
    "```\n",
    "\n",
    "compilación y ejecución\n",
    "```bash\n",
    "mpicc different_task.c -o different_task\n",
    "mpirun -np 4 different_task\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hello.f\n"
     ]
    }
   ],
   "source": [
    "%%writefile hello.f\n",
    "program hello_world\n",
    "include \"/usr/local/include/mpif.h\"\n",
    "include \"/usr/local/include/mpif-config.h\"\n",
    "integer ierr\n",
    "\n",
    "call MPI_INIT ( ierr )\n",
    "print *, \"Hello world\"\n",
    "call MPI_FINALIZE ( ierr )\n",
    "\n",
    "stop\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#cat /usr/local/include/mpif.h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/include/mpif.h:54: Error: Can't open included file 'mpif-config.h'\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gfortran -o hello hello.f -lmpi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Démosle una oportunidad a python\n",
    "\n",
    "\"*La optimización prematura es la raíz de todos los males*\"  Donald Knuth\n",
    "\n",
    "Una ventaja de C es la velocidad de ejecución de las aplicaciones, una desventaja es que la ingeniería de software es demasiado costosa como para desarrollar aplicaciones complejas. Lo ideal es hacer un prototipo rápido en un lenguaje de ingeniería de software más ágil y luego de tener resultados favorables hacer una implementación que se oriente a la velocidad en los resultados.\n",
    "\n",
    "En esta parte veremos algunos ejemplos de similares resultados a los anteriores pero en **python 2.7**\n",
    "\n",
    "## Recursos\n",
    "\n",
    "https://bitbucket.org/mpi4py/mpi4py\n",
    "\n",
    "http://pythonhosted.org/mpi4py/mpi4py.pdf\n",
    "\n",
    "http://pythonhosted.org/mpi4py/usrman/tutorial.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ej0.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ej0.py\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    \n",
    "    data = {'a': 7, 'b': 3.14}\n",
    "\n",
    "    comm.send(data, dest=1, tag=11)\n",
    "\n",
    "elif rank == 1:\n",
    "    \n",
    "    data = comm.recv(source=0, tag=11)\n",
    "    print data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 7, 'b': 3.14}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mpirun -np 2 python ej0.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ej_non_blocking.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ej_non_blocking.py\n",
    "\n",
    "#parecido al patron de diseno promesa\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = {'a': 7, 'b': 3.14}\n",
    "    req = comm.isend(data, dest=1, tag=11)\n",
    "    req.wait()\n",
    "elif rank == 1:\n",
    "    req = comm.irecv(source=0, tag=11)\n",
    "    data = req.wait()\n",
    "    print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 7, 'b': 3.14}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mpirun -np 3 python ej_non_blocking.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ej_numpy.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ej_numpy.py\n",
    "from mpi4py import MPI\n",
    "import numpy\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "# passing MPI datatypes explicitly\n",
    "if rank == 0:\n",
    "    data = numpy.arange(1000, dtype='i')\n",
    "    comm.Send([data, MPI.INT], dest=1, tag=77)\n",
    "elif rank == 1:\n",
    "    data = numpy.empty(1000, dtype='i')\n",
    "    comm.Recv([data, MPI.INT], source=0, tag=77)\n",
    "\n",
    "# automatic MPI datatype discovery\n",
    "if rank == 0:\n",
    "    data = numpy.arange(100, dtype=numpy.float64)\n",
    "    comm.Send(data, dest=1, tag=13)\n",
    "elif rank == 1:\n",
    "    data = numpy.empty(100, dtype=numpy.float64)\n",
    "    comm.Recv(data, source=0, tag=13)\n",
    "    print data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.   1.   2.   3.   4.   5.   6.   7.   8.   9.  10.  11.  12.  13.  14.\n",
      "  15.  16.  17.  18.  19.  20.  21.  22.  23.  24.  25.  26.  27.  28.  29.\n",
      "  30.  31.  32.  33.  34.  35.  36.  37.  38.  39.  40.  41.  42.  43.  44.\n",
      "  45.  46.  47.  48.  49.  50.  51.  52.  53.  54.  55.  56.  57.  58.  59.\n",
      "  60.  61.  62.  63.  64.  65.  66.  67.  68.  69.  70.  71.  72.  73.  74.\n",
      "  75.  76.  77.  78.  79.  80.  81.  82.  83.  84.  85.  86.  87.  88.  89.\n",
      "  90.  91.  92.  93.  94.  95.  96.  97.  98.  99.]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mpirun -n 2 python ej_numpy.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clase 3: Aspectos de Collective comunication\n",
    "\n",
    "### bibliografía\n",
    "http://mpitutorial.com/tutorials/mpi-broadcast-and-collective-communication/\n",
    "http://mpitutorial.com/tutorials/mpi-scatter-gather-and-allgather/\n",
    "\n",
    "Lo que hay que entender del Collective comunication es sobre la comunicación entre nodos\n",
    "\n",
    "### MPI_Bcast\n",
    "\n",
    "![](http://mpitutorial.com/tutorials/mpi-scatter-gather-and-allgather/broadcastvsscatter.png)\n",
    "\n",
    "Su uso es para enviar una copia de un objeto desde el nodo maestro a todos los esclavos, haremos un ejemplo de C y Python\n",
    "\n",
    "```c\n",
    "#include <mpi.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "        int rank;\n",
    "        int buf;\n",
    "        const int root=0;\n",
    "\n",
    "        MPI_Init(&argc, &argv);\n",
    "        MPI_Comm_rank(MPI_COMM_WORLD, &rank);\n",
    "\n",
    "        if(rank == root) {\n",
    "           buf = 777;\n",
    "        }\n",
    "\n",
    "        printf(\"[%d]: Before Bcast, buf is %d\\n\", rank, buf);\n",
    "\n",
    "        /* common region between all nodes*/\n",
    "        MPI_Bcast(&buf, 1, MPI_INT, root, MPI_COMM_WORLD);\n",
    "\n",
    "        printf(\"[%d]: After Bcast, buf is %d\\n\", rank, buf);\n",
    "\n",
    "        MPI_Finalize();\n",
    "        return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "compilamos y ejecutamos\n",
    "\n",
    "```bash\n",
    "mpicc bcast1.c -o bcast1\n",
    "mpirun bcast1\n",
    "```\n",
    "\n",
    "resultado\n",
    "\n",
    "```bash\n",
    "[0]: Before Bcast, buf is 777\n",
    "[0]: After Bcast, buf is 777\n",
    "[1]: Before Bcast, buf is 0\n",
    "[2]: Before Bcast, buf is 0\n",
    "[3]: Before Bcast, buf is 0\n",
    "[1]: After Bcast, buf is 777\n",
    "[2]: After Bcast, buf is 777\n",
    "[3]: After Bcast, buf is 777\n",
    "```\n",
    "\n",
    "\n",
    "Podemos implementar en python el mismo código\n",
    "\n",
    "```python\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_rank()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "root = 0\n",
    "\n",
    "buf = 0\n",
    "if rank == root:\n",
    "    buf = 777\n",
    "\n",
    "print \"[%d]: Before Bcast, buf is %d\\n\"%(rank, buf)\n",
    "buf = comm.bcast(buf, root=root)\n",
    "print \"[%d]: After Bcast, buf is %d\\n\"%(rank, buf)\n",
    "```\n",
    "\n",
    "y ejecutamos\n",
    "```bash\n",
    "mpirun -n 4 python bcast1.py\n",
    "```\n",
    "\n",
    "cuyo resultado es\n",
    "```bash\n",
    "[2]: Before Bcast, buf is 0\n",
    "[3]: Before Bcast, buf is 0\n",
    "[0]: Before Bcast, buf is 777\n",
    "[0]: Before Bcast, buf is 777\n",
    "[1]: Before Bcast, buf is 0\n",
    "[2]: Before Bcast, buf is 777\n",
    "[1]: Before Bcast, buf is 777\n",
    "[3]: Before Bcast, buf is 777\n",
    "```\n",
    "\n",
    "### MPI_Gather\n",
    "Recoje los resultados de cada nodo y los envia al nodo maestro en forma de lista de resultados\n",
    "![](http://mpitutorial.com/tutorials/mpi-scatter-gather-and-allgather/gather.png)\n",
    "\n",
    "```python\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_rank()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "root = 0\n",
    "\n",
    "buf = 0\n",
    "buf_list = None\n",
    "if rank == root:\n",
    "    buf = 777\n",
    "\n",
    "print \"[%d]: Before Bcast, buf is %d\\n\"%(rank, buf)\n",
    "buf = comm.bcast(buf, root=root)\n",
    "print \"[%d]: Before Bcast, buf is %d\\n\"%(rank, buf)\n",
    "buf = buf + rank\n",
    "buf_list = comm.gather(buf, root=root)\n",
    "\n",
    "if rank ==root:\n",
    "    print buf_list\n",
    "```\n",
    "\n",
    "### Tarea 2\n",
    "\n",
    "Existen dos formas de calcular la varianza de una muestra, por un lado la formula del momento central $$V[X]=E[(E[X]-X)^2]$$\n",
    "\n",
    "A nivel muestral $$s^2=\\frac{1}{n}\\sum_{i=1}^n (\\overline{x}-x_i)^2$$\n",
    "\n",
    "Dada una muestra aleatoria uniforme de 100 datos calcule la media y la desviación estandar usando bcast y gather para un número arbitrario de nodos. No se debe usar send y recv\n",
    "\n",
    "Los pasos son los siguientes.\n",
    "\n",
    "Primeo se debe calcular el promedio en paralelo $\\overline{x}$\n",
    "se debe enviar ese valor $\\overline{x}$ y la data $X$ una copia a cada nodo, para cada nodo se debe calcular $s^2=\\sum_{i={i_{rank}}}^{n_{rank}} (\\overline{x}-x_i)$ donde los limites inferior y superior se debe calcular dividiendo la data en función de la cantidad de nodos.\n",
    "\n",
    "finalmente enviar todos los resultados al nodos root mediante gather y calcular la varianza de la muestra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La función MPI_Scatter\n",
    "La función scatter es similar la función broadcast con la diferencia que no distribuye a cada nodo una copia del objeto si no que más bien solo una parte. Scatter toma una lista de objetos y distribuye a cada objeto el pedazo asociado al indice de la lista.\n",
    "\n",
    "```python\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    data = [(i+1)**2 for i in range(size)]\n",
    "    print data\n",
    "else:\n",
    "    data = None\n",
    "d = comm.scatter(data, root=0)\n",
    "\n",
    "d += 1\n",
    "\n",
    "data = comm.gather(d, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print data\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49705966039614502]\n"
     ]
    }
   ],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "if rank == 0:\n",
    "    n = 1000\n",
    "    rand = np.random.uniform(0,1,n)\n",
    "    data = np.array_split(rand, size)\n",
    "else:\n",
    "    data = None\n",
    "data_chunck = comm.scatter(data, root=0)\n",
    "\n",
    "avg = np.mean(data_chunck)\n",
    "\n",
    "avg = comm.gather(avg, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    avg = np.array(avg)\n",
    "    print \"gather es: \", avg\n",
    "    print \"el promedio de los promedios es: \", np.mean(avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Tarea 3\n",
    "Desarrolle un algoritmo en MPI que calcule la media, y la varianza de una distribución $X\\sim U(\\theta_1=0,\\theta_2=1)$ usando gather, scatter y broadcast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tarea 4 Simulación de montecarlo para un juego de bingo\n",
    "\n",
    "Considere el siguiente juego de facebook\n",
    "www.facebook.com/WoBingo/\n",
    "Desarrolle una simulación en paralelo que determine la distribución de la utilidad del jugador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Ejercicios\n",
    "\n",
    "1. Crear un programa en mpi-python que tome una lista de 9 elementos, particione esta lista en una partición de tres sublistas (partición). Envie cada una de estas listas a cada uno de los 3 nodos disponibles y encuentre una forma de calcular el promedio de la lista.\n",
    "\n",
    "```python\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "mean = None\n",
    "lp = l1 = l2 = l3 = None\n",
    "\n",
    "if rank == 0:\n",
    "    l = [1.0, 4.0, 5.0, 20.0, 3.0, 2.0, 0.0, 1.0, 1.0]\n",
    "    l1 = l[0:3]\n",
    "    l2 = l[3:6]\n",
    "    l3 = l[6:9]\n",
    "    \n",
    "    comm.send(l1, dest=1)\n",
    "    comm.send(l2, dest=2)\n",
    "    comm.send(l3, dest=3)\n",
    "\n",
    "if rank == 1:\n",
    "    lp = comm.recv(l1, source=0)\n",
    "    \n",
    "    mean = (lp[0] + lp[1] + lp[2]) / 3\n",
    "    \n",
    "    comm.send(mean, dest=0)\n",
    "    \n",
    "if rank == 2:\n",
    "    lp = comm.recv(l2, source=0)\n",
    "    \n",
    "    mean = (lp[0] + lp[1] + lp[2]) / 3\n",
    "    \n",
    "    comm.send(mean, dest=0)\n",
    "    \n",
    "if rank == 3:\n",
    "    lp = comm.recv(l3, source=0)\n",
    "    \n",
    "    mean = (lp[0] + lp[1] + lp[2]) / 3\n",
    "    \n",
    "    comm.send(mean, dest=0)\n",
    "\n",
    "if rank == 0:\n",
    "    \n",
    "    mean0 = comm.recv(mean, source=1)\n",
    "    mean1 = comm.recv(mean, source=2)\n",
    "    mean2 = comm.recv(mean, source=3)\n",
    "    \n",
    "    mean_result = (mean0 + mean1 + mean2)/3\n",
    "    print mean_result\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AllGather\n",
    "\n",
    "Hasta el momento hemos analizado dos tipos de procesos en MPI :\n",
    "\n",
    "1. Uno contra uno: send  & recv\n",
    "2. uno contra todos: bcast and scatter\n",
    "3. todos contra uno gather\n",
    "\n",
    "Ahora analizaremos un caso que tenemos pendiente: todos contra todos. La función allGather recibe los resultados de todos los nodos y los coloca en todos los nodos.\n",
    "![](http://mpitutorial.com/tutorials/mpi-scatter-gather-and-allgather/allgather.png)\n",
    "\n",
    "\n",
    "\n",
    "## Ejemplo de uso de AllGather\n",
    "\n",
    "```python\n",
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.rank\n",
    "\n",
    "xg = np.array(comm.allgather(rank)) + rank\n",
    "\n",
    "my_matrix = comm.gather(xg, root=0)\n",
    "\n",
    "if rank == 0:\n",
    "    print np.array(my_matrix)\n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "mpirun -n 4 python example_allgather.py\n",
    "```\n",
    "\n",
    "```bash\n",
    "[[0 1 2 3]\n",
    " [1 2 3 4]\n",
    " [2 3 4 5]\n",
    " [3 4 5 6]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depurando aplicaciones con mpi4py\n",
    "\n",
    "## Referencias\n",
    "\n",
    "https://bfroehle.com/2011/09/14/debugging-mpi-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
